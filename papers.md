# Calibration Metrics

## 2024

Lee et al. (ICML): [T-Cal: An Optimal Test for the Calibration of Predictive Models](https://icml.cc/virtual/2024/poster/35627)

## 2023

Gruber and Buettner (AISTATS): [Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition](https://arxiv.org/abs/2210.12256v3)

## 2022
Roelofs et al. (AISTATS): [Mitigating Bias in Calibration Error Estimation](https://arxiv.org/abs/2012.08668)

## 2021

Gupta et al. (ICLR): [Calibration of Neural Networks using Splines](https://arxiv.org/abs/2006.12800)
* top-k calibration

Minderer et al. (NeurIPS): [Revisiting the Calibration of Modern Neural Networks](https://arxiv.org/abs/2106.07998)

Karandikar et al. (NeurIPS): [Soft Calibration Objectives for Neural Networks](https://arxiv.org/abs/2108.00106)

Zhao et al. (NeurIPS): [Calibrating Predictions to Decisions: A Novel Approach to Multi-Class Calibration](https://arxiv.org/abs/2107.05719)

Chung et al.: [Uncertainty Toolbox: an Open-Source Library for Assessing, Visualizing, and Improving Uncertainty Quantification](https://arxiv.org/abs/2109.10254)

## 2020
Nixon et al. (ICML workshop): [Measuring Calibration in Deep Learning](https://arxiv.org/abs/1904.01685)
* SCE, ACE

Mukhoti et al. (NeurIPS): [Calibrating Deep Neural Networks using Focal Loss](https://arxiv.org/abs/2002.09437)

Zhao et al. (ICML): [Individual Calibration with Randomized Forecasting](https://arxiv.org/abs/2006.10288)

Zhang et al. (ICML): [Mix-n-Match: Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning](https://arxiv.org/abs/2003.07329)

## 2019
Kumar et al. (NeurIPS): [Verified Uncertainty Calibration](https://arxiv.org/abs/1909.10155)

Kull et al. (NeurIPS): [Beyond temperature scaling: Obtaining well-calibrated multiclass probabilities with Dirichlet calibration](https://arxiv.org/abs/1910.12656)
* Classwise-ECE

Vaicenavicius et al. (AISTATS): [Evaluating model calibration in classification](https://arxiv.org/abs/1902.06977)

Widmann et al. (NeurIPS): [Calibration tests in multi-class classification: A unifying framework](https://arxiv.org/abs/1910.11385)

Thulasidasan et al. (NeurIPS): [On Mixup Training: Improved Calibration and Predictive Uncertainty for Deep Neural Networks](https://arxiv.org/abs/1905.11001)

Hendrycks et al. (ICLR): [Deep Anomaly Detection with Outlier Exposure](https://arxiv.org/abs/1812.04606)
* RMS, MAD and Soft F1 Score

## 2018
Kumar et al. (ICML): [Trainable Calibration Measures for Neural Networks from Kernel Mean Embeddings](https://proceedings.mlr.press/v80/kumar18a.html)
* MMCE

## 2017
Guo et al. (ICML): [On Calibration of Modern Neural Networks](https://arxiv.org/abs/1706.04599)

Kull et al. (AISTATS): [Beta calibration: a well-founded and easily implemented improvement on logistic calibration for binary classifiers](https://proceedings.mlr.press/v54/kull17a.html)

## 2015
Naeini et al. (AAAI): [Obtaining Well Calibrated Probabilities Using Bayesian Binning](https://people.cs.pitt.edu/~milos/research/AAAI_Calibration.pdf)
* ECE, MCE
